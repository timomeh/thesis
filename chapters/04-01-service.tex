%!TEX root = ../thesis.tex
\section{Service: Entwurf und Implementierung}

\subsection{Elixir und Phoenix}

Bei Webanwendungen hängt (wie in anderen Domänen auch) die Wahl einer Programmiersprache des Webservices weniger davon ab, welches Problem die Anwendung lösen soll, sondern mehr von den Erfahrungen der im Projekt beteiligten Entwickler ab. Die Auswahl an serverseitigen Programmiersprachen ist groß, und jede Programmiersprache besitzt ihre eigenen Vorteile.

Die Wahl der Programmiersprache fiel für dieses Projekt auf \textbf{Elixir}.

Elixir wurde 2011 von José Valim veröffentlicht und ist somit eine relativ junge Programmiersprache. Elixir basiert jedoch auf Erlang, einer seit 1986 von Ericsson entwickelten Programmiersprache und Laufzeitumgebung. Das Erlang System ist u.a. für seine hohe Verfügbarkeit bekannt, es kann auf vielen Servern parallel laufen und aktualisiert werden, ohne die Anwendung stoppen zu müssen. Die Programmiersprache Erlang ist funktional, weshalb Elixir ebenfalls eine funktionale Programmiersprache ist.

Elixir wurde nicht gewählt, da darin schon Erfahrung besteht, sondern um Erfahrung in Elixir zu erlangen: Zu Beginn der Arbeit waren weder Kenntnisse in Elixir noch in Erlang vorhanden.

Als Webframework für Elixir wurde das bekannteste Framework gewählt: \textbf{Phoenix}.

Phoenix ist ein Framework für Webanwendungen nach dem \ac{MVC} Modell. Es beinhaltet viele nützliche Bestandteile wie eine Datenbank-Abstraktion (ähnlich zu einem \acs{ORM}\footnote{\acf{ORM}; da Elixir eine funktionale Programmiersprache ist und somit keine Objekte besitzt, ist der Begriff \acs{ORM} nicht zutreffend, jedoch vergleichbar mit ORMs aus anderen Sprachen.}) und eine einfache Implementierung von Websockets, welche im weiteren Verlauf der Arbeit zur Echtzeitkommunikation benötigt werden.

\subsection{Entwurf einer RESTful API}

\ac{REST} ist ein von Roy Fielding entworfener Architekturstil für \emph{``verteilte Hypermedia Systeme''}. Fielding nennt grundlegend zwei Bedingungen für ein solches System:

\begin{itemize}
  \item Die Trennung des Systems in eine Client-Server Architektur. Dies folgt dem Prinzip der ``Trennung der Belange'' \emph{(Separation of Concern)} in das Belangen der Nutzeroberflächer (Client) und das Belangen der Datenverwaltung (Server).
  \item Die Kommunikation zwischen Client und Server ist zustandslos \emph{(stateless)}. Der Client muss dem Server alle Daten übermitteln, die der Server zum Verständnis und Ausführen der Anfrage benötigt.\footnote{Im Gegensatz zu Sessions, bei denen auf dem Server Informationen zu jedem Client gespeichert werden.}
\end{itemize}

Alle Interaktionen bestehen grundlegend aus einer Ressource, einem Identifikator und einer Aktion \citep[12]{Webber2010}. REST ist kein Standard, daher kann sich die Implementierung von REST\footnote{Wenn wir REST implementieren, verwenden wir die Adjektivform \emph{``RESTful''}.} von Fall zu Fall unterscheiden. Bei Webanwendungen werden meist mindestens folgende Informationen aus dem HTTP Protokol genutzt:

\begin{itemize}
  \item Der Pfad der URL bestimmt die Ressource und den Identifikator.
  \item Die HTTP Methode bestimmt die auszuführende Aktion.
\end{itemize}

In Richardsons Maturity Model entspricht dies einem Level Two Service (vgl. \citep[20]{Webber2010}). Dabei werden auch HTTP Statuscodes genutzt, um dem Client einen standardisierten Status der Anfrage zu übermitteln.

Für den Service wurden die in Tabelle \ref{tab:rest-routes} definierten Endpunkte für eine RESTful API ausgearbeitet. Als Datenformat wurde JSON gewählt. Dies eignet sich besonders für die Verwendung in einem JavaScript-basierten Frontend Client.

\begin{table}[H]
  \footnotesize
  \begin{tabularx}{\textwidth}{| l | l | X |}
    \hline
    \textbf{Verb} & \textbf{Pfad} & \textbf{Beschreibung} \\ \hline
    GET & {\scriptsize \texttt{/projects}} & Auflisten aller Projekte \\ \hline
    POST & {\scriptsize \texttt{/projects}} & Erstellen eines neuen Projekts \\ \hline
    GET & {\scriptsize \texttt{/projects/:project\_id}} & Auslesen eines Projekts anhand seiner ID \\ \hline
    PUT & {\scriptsize \texttt{/projects/:project\_id}} & Aktualisieren eines Projekts anhand seiner ID \\ \hline
    DELETE & {\scriptsize \texttt{/projects/:project\_id}} & Löschen eines Projekts anhand seiner ID \\ \hline
    GET & {\scriptsize \texttt{/projects/:project\_id/pipelines}} & Auflisten aller Pipelines in einem Projekt \\ \hline
    POST & {\scriptsize \texttt{/projects/:project\_id/pipelines}} & Erstellen einer neuen Pipeline in einem Projekt \\ \hline
    GET & {\scriptsize \texttt{/projects/:project\_id/builds}} & Auflisten der letzten Builds eines Projekts anhand seiner ID \\ \hline
    GET & {\scriptsize \texttt{/pipelines/:pipeline\_id}} & Auslesen einer Pipeline anhand ihrer ID \\ \hline
    PUT & {\scriptsize \texttt{/pipelines/:pipeline\_id}} & Aktualisieren einer Pipeline anhand ihrer ID \\ \hline
    DELETE & {\scriptsize \texttt{/pipelines/:pipeline\_id}} & Löschen einer Pipeline anhand ihrer ID \\ \hline
    GET & {\scriptsize \texttt{/pipelines/:pipeline\_id/builds}} & Auflisten der letzten Builds einer Pipeline anhand ihrer ID \\ \hline
    GET & {\scriptsize \texttt{/builds/:build\_id}} & Auslesen eines Builds anhand seiner ID \\
    \hline\hline
    POST & {\scriptsize \texttt{/webhooks/receive}} & Endpunkt für Git Webhooks mit verschiedenen Aktionen, bspw. Erstellen eines neuen Builds\footnote{Diese Route entspricht nicht einer typischen RESTful Route, wird allerdings für das Empfangen von Webhooks auf diese benötigt} \\
    \hline
  \end{tabularx}
  \caption{RESTful API Routen}
  \label{tab:rest-routes}
\end{table}

\subsubsection{Die ``JSON API'' Spezifikation}
\label{subsec:jsonapi}

Zum Entwurf einer API im JSON Datenformat gibt es u.a. die Spezifikation ``JSON API''. Diese Spezifikation beinhaltet viele Konventionen zu den Daten, die zur API bzw. von der API gesendet werden.

Durch das Befolgen dieser Spezifikation lässt sich ein Level Three Service nach Richardsons Maturity Model implementieren (vgl. \citep[20]{Webber2010}): eingebettete Links zu anderen Ressourcen erfüllen die Bedingung des \emph{Hypermedia as the Engine of Application State (HATEOAS)}.

Es ist jedoch sehr aufwändig die gesamte JSON API Spezifikation zu befolgen. Daher wurde sich zur Implementierung vorerst auf die Top Level Struktur\footnote{vgl. http://jsonapi.org/format/\#document-top-level} beschränkt. Diese besitzt drei Teile:

\begin{itemize}
  \item \texttt{data} beinhaltet alle Daten der Ressource.
  \item \texttt{error} beinhaltet alle Fehler, die durch die Anfrage entstanden sind.
  \item \texttt{meta} beinhaltet optionale Informationen zur Anfrage.
\end{itemize}

\lstinputlisting
  [caption={Vereinfachte Struktur der JSON API Ausgabe},
  label={lst:jsonapi-simple-example}]
  {snippets/jsonapi-example.json}

\subsubsection{Aufruf der API}

Auf die Details der Implementierung der API wird nicht genauer eingegangen. Folgende Beispiele verdeutlichen jedoch die Nutzung der API mit dem \ac{CLI} \texttt{curl}. In einem Browser-Client kann hierfür auch auf ähnlich Weise die fetch-API genutzt werden.

\lstinputlisting
  [caption={API Beispiel: Auflistung aller Pipelines mit angelegter Pipeline}]
  {snippets/api-example-get-pipelines-again.txt}

\lstinputlisting
  [caption={API Beispiel: Anlegen einer Pipeline}]
  {snippets/api-example-create-pipeline.txt}

\lstinputlisting
  [caption={API Beispiel: Löschen einer Pipeline}]
  {snippets/api-example-delete-pipeline.txt}

Sollten ungültige Attribute übergeben werden, wird – wie in der JSON API Spezifikation definiert (siehe Sektion \ref{subsec:jsonapi}) – eine passende Fehlermeldung ausgegeben. In Beispiel \ref{lst:api-example-update-error} wird zur Erzeugung eines Fehlers der Titel der Pipeline auf eine Nummer aktualisiert.

\lstinputlisting
  [caption={API Beispiel: Ungültige Aktualisierung einer Pipeline},
  label={lst:api-example-update-error}]
  {snippets/api-example-update-pipeline-error.txt}


\subsection{Konfiguration einer Pipeline}

Über die API werden nur die Attribute der Pipeline angelegt, nicht jedoch die Stages, Gruppen und Schritte der Pipeline (siehe Sektion \ref{subsec:uml}). Dies wurde bewusst nicht über die API implementiert. Die Stages, Gruppen und Schritte sollen nämlich aus einer Konfigurationsdatei ausgelesen werden.

Das Anlegen komplexer Pipelines mit mehreren Stages, Abschnitten und verschachtelten Gruppen gestaltet sich über eine UI schwierig. Eine Konfigurationsdatei ist in solchen Fällen vorteilhafter und besonders bei Entwicklern beliebt. Ein sehr großer Vorteil ist, dass die Konfigurationsdatei direkt auch unter Versionskontrolle steht, wenn sie als Datei im Projekt angelegt ist.

Eine Datei namens `.warp.yml` im Dokumentenstamm des Projekts beinhaltet den Aufbau aller Pipelines im Projekt. Die Konfigurationsdatei wird ausgelesen und vor dem Starten des Build-Prozesses als Entitäten gespeichert.

Die Zugehörigkeit zwischen Pipeline in der Datenbank und in der Konfigurationsdatei wird über einen Identifikator bestimmt. (Vgl. \texttt{konfiguration\_\allowbreak inidentifikator} in Abbildung \ref{fig:uml} bzw. \texttt{human\_id} in der letztendlichen Implementation, vgl. Sektion \ref{subsec:api-usage})

Die Konfigurationsdatei ist im YAML-Format notiert. YAML\footnote{http://yaml.org/} ist ein menschenfreundlicher Standard. Im Gegensatz zu JSON, was zur API-Kommunikation genutzt wird, besitzt YAML beispielweise Kommentare.

Quelltext \ref{lst:example-config} zeigt eine mögliche Konfiguration. Bei \texttt{steps\_\allowbreak parallel} und \texttt{steps\_\allowbreak serial} handelt es sich um die Gruppen, deren Schritte entweder seriell oder parallel ausgeführt werden. In diesem Beispiel wird auch ersichtlich, wie sich mehrere Abschnitte ineinander verschachteln lassen.

\lstinputlisting
  [caption={Konfiguration einer Pipeline im YAML Format},
  label={lst:example-config}]
  {snippets/config-example-yml.yml}

Die Konfigurationsdatei enthält noch andere Besonderheiten, wie u.a. ein \texttt{include} Befehl, mit dem Stages, Gruppen und Schritte zwischen in mehreren Pipelines genutzt werden können. Auf weitere Besonderheiten und Implementierungen hierzu wird nicht eingegangen.

\subsubsection{Zuordnung einer Pipeline zu einem Branch}
\label{subsec:git-reference}

In der Praxis ist es sinnvoll für verschiedene Git Branches auch unterschiedliche Build Prozesse auszuführen. Folgendes Szenario zeigt einen dazu passenden Anwendungsfall:

Für alle Feature Branches eines Projekts wird nur ein \ac{CI} Build durchgeführt, um zu verfolgen, ob ein Branch integrierbar bleibt. Es ist nicht nötig, solche Branches auf eine Serverumgebung zu deployen. Wurde ein Feature fertiggestellt, wird der Feature Branch in den Branch \texttt{master} gemerged. Bei Änderungen an diesem Branch wird ein Build Prozess durchgeführt, der zudem auch ein Deployment auf eine Staging-Umgebung beinhaltet. Ein weiterer Branch \texttt{production} ist mit einem Build Prozess verbunden, der ein Deployment auf eine Produktions-Umgebung durchführt.

Der in Abschnitt \ref{subsec:uebersicht-anwendung} beschriebene Webhook wird bei jedem Push in das Remote Repository ausgeführt. Aus ihm müssen wir auslesen, welche Pipeline dem Push zugeordnet ist. Dies kann über die Git Reference gelöst werden, aus der man den Namen des zugehörigen Branches und sogar auch den Namen eines Git Tags auslesen kann.

Somit wird in der Pipeline konfiguriert, welcher Git Reference sie zugeordnet ist. Im gerade beschriebenen Szenario sollte eine Pipeline für \emph{alle} Feature Branches ausgeführt werden. Feature Branches besitzen üblicherweise das Präfix \texttt{feature/} (z.B. \texttt{feature/worker\allowbreak -refactor} oder \texttt{feature/queue\allowbreak -implementation}). Es wäre jedoch unpraktisch, wenn für jeden neuen Feature Branch eine weitere, identische Pipeline angelegt werden muss, bei der sich nur die Git Reference unterscheidet.

Als universelle Lösung für dieses Problem wird ein regulärer Ausdruck als Zuordnung zur Git Reference verwendet. Ein zum Szenario passender Ausdrück wäre \texttt{feature/.*\$}. Über ihn können alle Feature Branches der gleichen Pipeline zugeordnet werden.

In der Datenstruktur (Abbildung \ref{fig:uml}) entspricht dem Feld \emph{git\_ref\_auslöser}.

\subsubsection{Nachteile der Konfigurationsdatei}

Ursprünglich wurde nicht geplant, dass eine Pipeline über die API angelegt werden muss. Alle Konfigurationen sollten über die Konfigurationsdatei ausgelesen werden.

In der Praxis hat sich dies als problematisch erwiesen. Bei jedem Webhook hätte ein Build-Prozess initialisiert werden müssen, um in der Konfigurationsdatei nach einer passenden Git Reference (siehe Abschnitt \ref{subsec:git-reference}) zu suchen. Wenn keine passende Git Reference gefunden wird, müsste der Build-Prozess sofort abgebrochen werden.

Da dies einen großen Overhead erzeugt, wurden bestimmte Attribute der Pipeline, vor allem der Reguläre Ausdruck der Git Reference, in die Datenbank ausgelagert. Bei einem einkommenden Webhook kann dadurch direkt in der Datenbank nach einer zugehörigen Pipeline gesucht werden. Wenn keine gefunden wird, muss auch kein Build-Prozess initialisiert werden.

\subsection{Ablauf eines Build-Prozesses}
\label{subsec:ablauf-build}

Die Ausführung eines Build-Prozesses wird anfangs in einer Warteschlange pro Pipeline zwischengespeichert. Build-Prozesse einer Pipeline sollen nicht simultan ausgeführt werden.

Für jeden Eintrag in der Warteschlange werden folgende Schritte ausgeführt:

\begin{description}
  \item[Schritt 1:] Erstellen einer temporären Umgebung, in dem der Build-Prozess ausgeführt wird. In diesem Fall ein Ordner, in dem die Ausführung stattfindet.
  \item[Schritt 2:] \texttt{git clone} des Repositories in der temporäre Umgebung.
  \item[Schritt 3:] \texttt{git checkout} des Repositories an den im Webhook übertragenen Commit SHA.
  \item[Schritt 4:] Auslesen der Konfigurationsdatei und speichern der Stages, Gruppen und Schritte des Build-Prozesses in der Datenbank.
  \item[Schritt 5:] Starten des \textbf{Build Workers}.
  \item[Schritt 6:] Darin werden nacheinander die Stages aufgerufen. Eine Stage ist ein \textbf{serieller Group Worker}.
  \item[Schritt 7:] In jeder Stage werden weitere Gruppen oder Schritte ausgeführt, parallel oder seriell (\textbf{Group Worker} bzw. \textbf{Step Worker}).
  \item[Schritt 8:] Falls vorhanden werden rekursiv weitere Gruppen oder Schritte ausgeführt.
  \item[Schritt 9:] Wurden alle Stages ausgeführt, wird der Build Worker beendet.
  \item[Schritt 10:] Löschen der temporären Umgebung.
\end{description}

Das Ausführen des eigentlichen Build-Prozesses (Schritte 5 bis 9) und dessen Abhängigkeiten zu anderen Workern lässt sich als Prozess grafisch verständlicher in einem vereinfachten Ablaufdiagramm (Abbildung \ref{fig:ablauf-build-prozess}) darstellen.

\begin{figure}[h]
  \caption{Vereinfachtes Ablaufdiagramm des Build-Prozesses}
  \label{fig:ablauf-build-prozess}
  \centering
    \includegraphics[width=\textwidth]{assets/worker_diagram}
\end{figure}

In Abbildung \ref{fig:ablauf-build-prozess} ist zu sehen, wie von links nach rechts der Ablauf des Build-Prozesses geleitet wird, bis ganz rechts jeweils ein \emph{Step Worker} den eigentlichen Befehl ausführt.

Verschachtelte Worker melden ihrem übergeordneten Worker, wenn sie ihre Arbeit beendet haben. Der übergeordnete Worker kann darauf weitere Worker starten, oder selbst seinem übergeordneten Worker melden, dass er beendet ist. Die Abfolge findet also rein über Kommunikation zwischen den einzelnen Workern statt.

Auch wenn bei einem Schritt ein Fehler auftritt, wird dem übergeordneten Worker der Fehler gemeldet. Dieser beendet nun möglicherweise aktive Kinder und meldet den Fehler seinem übergeordneten Worker. Somit werden Fehler im Schneeballprinzip im gesamten Prozess bekannt gegeben und der gesamte Prozess geleitet abgebrochen.

Alle Worker übermitteln über einen Websocket die aktualisierten Daten der jeweiligen Entität, damit die Änderungen auch direkt Client angezeigt werden können.

\subsection{Entwurf der Worker}

Ein \textbf{Worker} ist ein Konzept in der Software-Programmierung, bei dem eine Aufgabe einem nebenläufigen Prozess zugeteilt wird. Hat ein Worker seine Arbeit beendet, ruft er einen Callback auf, um nächste Schritte auszuführen. WARP nutzt Worker zur Implementierung eines Build-Prozesses.

Erlang (und somit auch Elixir) besitzt die Möglichkeit nebenläufige Prozesse zu starten. Diese sind keine Betriebssystem-Prozesse, sondern eigene Prozesse der Erlang VM. Durch die ressourcensparende Natur dieser Prozesse erlaubt es Erlang, eine Vielzahl von Prozessen in einer Anwendung zu verwalten. \citep[133]{Armstrong2007}

Prozesse kommunizieren untereinander mit Nachrichten und können besitzen einen Speicher bzw. Zustand (State). Diese Eigenschaften eignen sich sehr gut zur Implementierung der in Sektion \ref{subsec:ablauf-build} beschriebenen Worker.

\subsubsection{Aufteilung in isolierte Worker}
\label{subsec:aufteilung-der-worker}

Die Worker für den Build-Prozess wurden, getrennt nach ihrer Aufgabe, in verschiedene Module aufgeteilt:

\begin{description}
  \item [PipelineQueue] Eine Queue für Build-Prozesse jeder Pipeline.
  \item [InitWorker] Initialisiert den Build-Prozess von der Erstellung des temporären Ordners, über \texttt{git clone} und \texttt{git checkout} bis hin zum Abspeichern der Stages, Abschnitte und Schritte aus der Konfigurationsdatei.
  \item [BuildWorker] Verwaltet die Build-Entität und startet die darin befindlichen Stages.
  \item [GroupWorker] Verwaltet die Stage- \emph{oder} Abschnitt-Entität und startet die darin befindlichen Abschnitte oder Schritte. Stage und Abschnitt unterscheiden sich nur darin, dass Stages immer seriell ausgeführt werden, weshalb diese in einem Modul zusammengefasst werden können.
  \item [StepWorker] Verwaltet die Schritt-Entität und führt ihren Befehl aus.
\end{description}

\subsubsection{Kommunikation zwischen Workern}

Ein \emph{GenServer} (generic server) ist ein Elixir Prozess, der bestimmte Funktionen bereitstellt, um State im Prozess zu speichern und die Kommunikation zwischen Prozessen zu erleichtern. Er eignet sich zur Implementierung der Worker und deren Kommunikation untereinander.

Mittels \texttt{call/3} und \texttt{cast/2} lassen sich Nachrichten an einen GenServer senden, worauf der GenServer eine Funktion ausführen kann. \texttt{call} ist eine synchrone Nachricht: nach Aufruf der Funktion wird auf eine Antwort gewartet. Im Gegensatz dazu ist \texttt{cast} eine asynchrone Nachricht, die keine Antwort erwartet.

Der GenServer nimmt diese Nachrichten über die Callbacks \texttt{handle\_\allowbreak call/3} und \texttt{handle\_\allowbreak cast/2} an.

\subsection{Implementierung eines Workers}
\label{subsec:implementierung-worker}

In diesem Abschnitt wird die Implementierung eines Workers mittels GenServer anhand des Build-Workers verdeutlicht. Er ist für die Build-Entität verantwortlich, startet Stages und reagiert auf Callbacks der Stage.

Ein GenServer kann mit \texttt{start/3} oder \texttt{start\_link/3} gestartet werden. Letzteres startet den GenServer unter einem \emph{Supervision Tree}. Der GenServer wird automatisch beendet, wenn der aufrufende Prozess beendet wurde. Da der Build-Prozess eigenständig ausgeführt werden soll, wird \texttt{start/3} verwendet.

\lstinputlisting
  [caption={BuildWorker.ex: Initialisierung},
  language=elixir,
  firstline=1,
  lastline=12]
  {snippets/build-worker.ex}

Der Name \texttt{start} ist irreführend: es wird noch nicht der Build-Prozess gestartet, sondern vorerst der Build-Worker initialisiert.

Als State wird im Build-Worker die Datenbank-Entität des Builds, welche auch alle verschachtelten Entitäten besitzt, und der Index der aktiven Stage gespeichert. Außerdem wird die ID des Projekts gespeichert. Sie wird dazu benötigt, um Nachrichten über Websockets zu senden. Diese Nachrichten werden in einen Kanal gesendet, der über die Projekt-ID identifiziert wird.

Der Befehl \texttt{Process.flag(:trap\_exit,\allowbreak\ true)} sorgt dafür, dass vor Beenden des GenServers die Funktion \texttt{terminate/2} aufgerufen wird. Diese wird am Ende des BuildWorkers noch benötigt.

Als Hilfsmittel stellt Build-Worker eine Funktion bereit, um den Build-Prozess zu starten. Zum Starten wird die Nachricht \texttt{:run} an den Build-Worker übermittelt.

\lstinputlisting
  [caption={BuildWorker.ex: Client-Funktionen},
  language=elixir,
  firstline=14,
  lastline=16]
  {snippets/build-worker.ex}

Mittels der beiden Funktionen \texttt{start/2} und \texttt{run/1} kann schon der Build-Worker initialisiert und gestartet werden.

\lstinputlisting
  [caption={Beispiel zum Initialiseren und Starten des BuildWorkers},
  language=elixir]
  {snippets/build-worker-start.ex}

Der GenServer muss nun auf die Nachricht \texttt{:run} reagieren. Da es sich um einen \texttt{cast/2} handelt, wird keine Antwort darauf gesendet. In diesem Callback wird die nächste Stage ausgeführt. Ist noch keine Stage aktiv, wird die erste Stage ausgeführt.

\lstinputlisting
  [caption={BuildWorker.ex: Empfangen einer cast-Nachricht zum Starten des Build-Workers},
  language=elixir,
  firstline=18,
  lastline=30]
  {snippets/build-worker.ex}

Die Funktion \texttt{run\_\allowbreak next\_\allowbreak stage/1} erhöht den Index der aktiven Stage und führt die entsprechende Stage als GroupWorker aus (vgl. Abschnitt \ref{subsec:aufteilung-der-worker}):

\lstinputlisting
  [caption={BuildWorker.ex: Starten eines GroupWorkers für eine Stage},
  language=elixir,
  firstline=32,
  lastline=45]
  {snippets/build-worker.ex}

An dieser Stelle der Ausführung läuft ein ausgegliederter Prozess, der eine Stage abarbeitet. Wir können diesen Prozess als Blackbox betrachten: was genau in ihm passiert, ist für den BuildWorker irrelevant. Wird der GroupWorker beendet, empfängt der BuildWorker eine entsprechende Nachricht.

\lstinputlisting
  [caption={BuildWorker.ex: Nachricht über erfolgreiches Beenden des GroupWorkers},
  language=elixir,
  firstline=47,
  lastline=63]
  {snippets/build-worker.ex}

Wenn es weitere Stages gibt, wird dort die nächste Stage aufgerufen. Wurde die letzte Stage des Builds beendet, wird auch der BuildWorker beendet.

Sollte der GroupWorker mit einem Fehler beendet werden, beispielsweise weil ein Schritt nicht erfolgreich war, werden wir hierüber auch benachrichtigt. Der BuildWorker reagiert in diesem Fall darauf, dass er sich ebenfalls mit einem Fehler beendet.

\lstinputlisting
  [caption={BuildWorker.ex: Nachricht über fehlerhaftes Beenden des GroupWorkers},
  language=elixir,
  firstline=65,
  lastline=68]
  {snippets/build-worker.ex}

Wie oben erwähnt, wird direkt vor dem Beenden des GenServers die Funktion \texttt{terminate/2} aufgerufen. Hier wird u.a. der Status des Builds in der Datenbank aktualisiert.

\lstinputlisting
  [caption={BuildWorker.ex: Terminieren},
  language=elixir,
  firstline=70,
  lastline=87]
  {snippets/build-worker.ex}

An einigen Stellen des Workers wird die Funktion \texttt{broadcast/2} aufgerufen. Sie sendet über Phoenix' PubSub Modul eine Nachricht über einen Websocket.

\lstinputlisting
  [caption={BuildWorker.ex: Senden einer Nachricht über einen Websocket},
  language=elixir,
  firstline=89,
  lastline=99]
  {snippets/build-worker.ex}

Die Funktion \texttt{log/2} dient zum Logging und Debugging. Auf sie wird nicht weiter eingegangen.

Die Implementierung der anderen Worker gestaltet sich ähnlich. Selbstverständlich unterscheiden sich einige Stellen und werden komplexer, beispielsweise das serielle oder parallele Ausführen von Schritten in einer Gruppe. Der Ablauf des BuildWorkers und die Kommunikation zum GroupWorker ist jedoch übertragbar auf andere Worker.

\subsection{Isolation der Build-Steps}

In der aktuellen Implementation wird der Build-Prozess in einem temporären Ordner ausgeführt. Die Befehle werden in einer Shell der Maschine ausgeführt, auf der der Service ausgeführt wird.

Für einen Service in Produktion eignet sich dies allerdings nicht. Die Befehle (Build Steps) sollten isoliert voneinander, bestenfalls in Instanzen einer virtuellen Maschine (z.B. Docker) ausgeführt werden. Eine solche Implementation sprengt den Umsatz dieser Arbeit, daher wurde ein sehr simpler Ansatz verwendet.
